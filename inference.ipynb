{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d966ee66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T18:45:52.809979Z",
     "iopub.status.busy": "2025-07-19T18:45:52.809662Z",
     "iopub.status.idle": "2025-07-19T18:45:57.888153Z",
     "shell.execute_reply": "2025-07-19T18:45:57.887134Z"
    },
    "papermill": {
     "duration": 5.085196,
     "end_time": "2025-07-19T18:45:57.889843",
     "exception": false,
     "start_time": "2025-07-19T18:45:52.804647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# REPRODUCIBILITY SETUP - Set Seeds for Consistent Results\n",
    "################################################################################\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set seeds for reproducibility across all libraries\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # For transformers models\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    \n",
    "\n",
    "# Set the global seed\n",
    "set_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16a03e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T18:45:57.898128Z",
     "iopub.status.busy": "2025-07-19T18:45:57.897676Z",
     "iopub.status.idle": "2025-07-19T18:46:30.066219Z",
     "shell.execute_reply": "2025-07-19T18:46:30.065197Z"
    },
    "papermill": {
     "duration": 32.174774,
     "end_time": "2025-07-19T18:46:30.067996",
     "exception": false,
     "start_time": "2025-07-19T18:45:57.893222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 18:46:15.220149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752950775.450419      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752950775.515159      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# IMPORT REQUIRED LIBRARIES\n",
    "################################################################################\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertPreTrainedModel,\n",
    "    BertModel\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caa1cc36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T18:46:30.076017Z",
     "iopub.status.busy": "2025-07-19T18:46:30.075373Z",
     "iopub.status.idle": "2025-07-19T18:46:30.085977Z",
     "shell.execute_reply": "2025-07-19T18:46:30.084646Z"
    },
    "papermill": {
     "duration": 0.016421,
     "end_time": "2025-07-19T18:46:30.087507",
     "exception": false,
     "start_time": "2025-07-19T18:46:30.071086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# CUSTOM MODEL DEFINITION (Same as Training)\n",
    "################################################################################\n",
    "class BertForMultiTaskClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_emotions=7, num_intensities=3):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier_emotion = nn.Linear(config.hidden_size, num_emotions)\n",
    "        self.classifier_intensity = nn.Linear(config.hidden_size, num_intensities)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "        logits_emotion = self.classifier_emotion(pooled_output)\n",
    "        logits_intensity = self.classifier_intensity(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            emotion_labels = labels[:, 0]\n",
    "            intensity_labels = labels[:, 1]\n",
    "            loss_emotion = loss_fct(logits_emotion, emotion_labels)\n",
    "            loss_intensity = loss_fct(logits_intensity, intensity_labels)\n",
    "            loss = loss_emotion + loss_intensity\n",
    "\n",
    "        output = (logits_emotion, logits_intensity) + outputs[2:]\n",
    "        return ((loss,) + output) if loss is not None else output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30caf2f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T18:46:30.095479Z",
     "iopub.status.busy": "2025-07-19T18:46:30.095152Z",
     "iopub.status.idle": "2025-07-19T18:46:30.102636Z",
     "shell.execute_reply": "2025-07-19T18:46:30.101532Z"
    },
    "papermill": {
     "duration": 0.013718,
     "end_time": "2025-07-19T18:46:30.104237",
     "exception": false,
     "start_time": "2025-07-19T18:46:30.090519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# DATASET CLASS FOR INFERENCE (Same as Training)\n",
    "################################################################################\n",
    "class EmotionsDataset(Dataset):\n",
    "    def __init__(self, texts, emotion_labels=None, intensity_labels=None, tokenizer=None, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.intensity_labels = intensity_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze() for k, v in encoding.items()}\n",
    "        \n",
    "        # For inference, we might not have labels\n",
    "        if self.emotion_labels is not None and self.intensity_labels is not None:\n",
    "            emotion_label = self.emotion_labels[idx]\n",
    "            intensity_label = self.intensity_labels[idx]\n",
    "            item[\"labels\"] = torch.tensor([emotion_label, intensity_label], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b10ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T18:46:30.111862Z",
     "iopub.status.busy": "2025-07-19T18:46:30.111457Z",
     "iopub.status.idle": "2025-07-19T18:46:30.873361Z",
     "shell.execute_reply": "2025-07-19T18:46:30.872226Z"
    },
    "papermill": {
     "duration": 0.767741,
     "end_time": "2025-07-19T18:46:30.874915",
     "exception": false,
     "start_time": "2025-07-19T18:46:30.107174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found model directory: /kaggle/input/emotion-model/saved_bangla_emotion_model\n",
      "Contents: ['labels_mapping.json', 'config.json', 'tokenizer.json', 'tokenizer_config.json', 'model.safetensors', 'special_tokens_map.json', 'vocab.txt']\n",
      "📋 Loaded emotion categories: ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise']\n",
      "📋 Loaded intensity categories: ['0.0', '1.0', '2.0']\n",
      "✅ Tokenizer loaded successfully\n",
      "✅ Model loaded successfully and set to evaluation mode\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# LOAD TRAINED MODEL AND TOKENIZER\n",
    "################################################################################\n",
    "\n",
    "# Model paths\n",
    "MODEL_DIR = \"/kaggle/input/emotion-model/saved_bangla_emotion_model\"  # Adjust path if needed\n",
    "LABELS_FILE = os.path.join(MODEL_DIR, \"labels_mapping.json\")\n",
    "\n",
    "# Check if model directory exists\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    print(f\"❌ Model directory not found: {MODEL_DIR}\")\n",
    "    print(\"Please ensure the model was saved during training or adjust the path.\")\n",
    "else:\n",
    "    print(f\"✅ Found model directory: {MODEL_DIR}\")\n",
    "    print(f\"Contents: {os.listdir(MODEL_DIR)}\")\n",
    "\n",
    "# Load labels mapping\n",
    "try:\n",
    "    with open(LABELS_FILE, 'r') as f:\n",
    "        labels_mapping = json.load(f)\n",
    "    \n",
    "    EMOTIONS = labels_mapping[\"emotions\"]\n",
    "    INTENSITIES = labels_mapping[\"intensities\"]\n",
    "    emotion_to_id = labels_mapping[\"emotion_to_id\"]\n",
    "    id_to_emotion = labels_mapping[\"id_to_emotion\"]\n",
    "    intensity_to_id = labels_mapping[\"intensity_to_id\"]\n",
    "    id_to_intensity = labels_mapping[\"id_to_intensity\"]\n",
    "    \n",
    "    print(f\"📋 Loaded emotion categories: {EMOTIONS}\")\n",
    "    print(f\"📋 Loaded intensity categories: {INTENSITIES}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Labels mapping file not found: {LABELS_FILE}\")\n",
    "    print(\"Creating default mappings...\")\n",
    "    # Default mappings (adjust based on your actual data)\n",
    "    EMOTIONS = ['joy', 'fear', 'anger', 'sadness', 'disgust', 'surprise', 'love']\n",
    "    INTENSITIES = ['low', 'medium', 'high']\n",
    "    emotion_to_id = {emotion: idx for idx, emotion in enumerate(EMOTIONS)}\n",
    "    id_to_emotion = {idx: emotion for idx, emotion in enumerate(EMOTIONS)}\n",
    "    intensity_to_id = {intensity: idx for idx, intensity in enumerate(INTENSITIES)}\n",
    "    id_to_intensity = {idx: intensity for idx, intensity in enumerate(INTENSITIES)}\n",
    "\n",
    "# Load tokenizer\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "    print(\"✅ Tokenizer loaded successfully\")\n",
    "except:\n",
    "    print(\"❌ Failed to load tokenizer from model directory\")\n",
    "    print(\"Loading tokenizer from Hugging Face...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
    "\n",
    "# Load model\n",
    "try:\n",
    "    model = BertForMultiTaskClassification.from_pretrained(\n",
    "        MODEL_DIR, \n",
    "        num_emotions=len(EMOTIONS),\n",
    "        num_intensities=len(INTENSITIES)\n",
    "    )\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    print(\"✅ Model loaded successfully and set to evaluation mode\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to load model: {e}\")\n",
    "    print(\"You may need to train the model first or check the model path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a6656d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T18:46:30.882341Z",
     "iopub.status.busy": "2025-07-19T18:46:30.881997Z",
     "iopub.status.idle": "2025-07-19T18:46:30.893285Z",
     "shell.execute_reply": "2025-07-19T18:46:30.891612Z"
    },
    "papermill": {
     "duration": 0.016948,
     "end_time": "2025-07-19T18:46:30.894944",
     "exception": false,
     "start_time": "2025-07-19T18:46:30.877996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Inference function defined\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# INFERENCE FUNCTION (Same Logic as Training Test Set Evaluation)\n",
    "################################################################################\n",
    "\n",
    "def predict_emotions_and_intensities(texts, model, tokenizer, batch_size=32):\n",
    "    \"\"\"\n",
    "    Perform inference on a list of texts using the trained model.\n",
    "    Returns predictions in the same format as training evaluation.\n",
    "    \"\"\"\n",
    "    # Create dataset for inference\n",
    "    dataset = EmotionsDataset(texts, tokenizer=tokenizer)\n",
    "    \n",
    "    # Create data loader\n",
    "    from torch.utils.data import DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Store predictions\n",
    "    all_emotion_logits = []\n",
    "    all_intensity_logits = []\n",
    "    \n",
    "    print(f\"🔮 Processing {len(texts)} texts for inference...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Move batch to device (CPU/GPU)\n",
    "            device = next(model.parameters()).device\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
    "            \n",
    "            # Get model predictions\n",
    "            outputs = model(**batch)\n",
    "            logits_emotion, logits_intensity = outputs[0], outputs[1]\n",
    "            \n",
    "            # Store logits\n",
    "            all_emotion_logits.append(logits_emotion.cpu().numpy())\n",
    "            all_intensity_logits.append(logits_intensity.cpu().numpy())\n",
    "    \n",
    "    # Concatenate all predictions\n",
    "    emotion_logits = np.concatenate(all_emotion_logits, axis=0)\n",
    "    intensity_logits = np.concatenate(all_intensity_logits, axis=0)\n",
    "    \n",
    "    # Convert logits to predictions (same as training)\n",
    "    emotion_predictions = np.argmax(emotion_logits, axis=1)\n",
    "    intensity_predictions = np.argmax(intensity_logits, axis=1)\n",
    "    \n",
    "    # Convert predictions to labels\n",
    "    predicted_emotions = [id_to_emotion[str(pred)] for pred in emotion_predictions]\n",
    "    predicted_intensities = [id_to_intensity[str(pred)] for pred in intensity_predictions]\n",
    "    \n",
    "    # Create results dataframe (same format as training)\n",
    "    results_df = pd.DataFrame({\n",
    "        'text': texts,\n",
    "        'predicted_emotion_id': emotion_predictions,\n",
    "        'predicted_intensity_id': intensity_predictions,\n",
    "        'predicted_emotion': predicted_emotions,\n",
    "        'predicted_intensity': predicted_intensities\n",
    "    })\n",
    "    \n",
    "    print(\"✅ Inference completed successfully\")\n",
    "    return results_df, emotion_logits, intensity_logits\n",
    "\n",
    "print(\"🔧 Inference function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee230acf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T18:46:30.904675Z",
     "iopub.status.busy": "2025-07-19T18:46:30.904313Z",
     "iopub.status.idle": "2025-07-19T18:46:30.911167Z",
     "shell.execute_reply": "2025-07-19T18:46:30.909960Z"
    },
    "papermill": {
     "duration": 0.013705,
     "end_time": "2025-07-19T18:46:30.912780",
     "exception": false,
     "start_time": "2025-07-19T18:46:30.899075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Prepared 7 sample texts for testing\n",
      "1. আমি খুব খুশি আজকে।\n",
      "2. এটা খুব দুঃখজনক খবর।\n",
      "3. আল্লাহ তাদের সাহায্য করুন, আর জালিমদের ধ্বংস করুন, আমিন\n",
      "4. আবার হরতাল করে মানুষের মধ্যে আতংক তৈরি করার পাঁয়তারা।\n",
      "5. এই দৃশ্যটা দেখে আমি অবাক হয়ে গেছি।\n",
      "6. ভগ্যিস ও মানুষ হয়ে জন্মায়নি.\n",
      "7. ভোটের হার কম হলে দোষ, বেশি হলে দোষ, ভোটের সময় মারামারি না হওয়াটাও দোষের, আসলে সমালোচকরা কী চায় ??\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# SAMPLE TEXT DATA FOR TESTING (Bangla Text Examples)\n",
    "################################################################################\n",
    "\n",
    "# Sample Bangla texts for testing (you can replace with your own texts)\n",
    "sample_texts = [\n",
    "    \"আমি খুব খুশি আজকে।\",  # I am very happy today\n",
    "    \"এটা খুব দুঃখজনক খবর।\",  # This is very sad news\n",
    "    \"আল্লাহ তাদের সাহায্য করুন, আর জালিমদের ধ্বংস করুন, আমিন\",  # This matter has made me angry\n",
    "    \"আবার হরতাল করে মানুষের মধ্যে আতংক তৈরি করার পাঁয়তারা।\",  # You have done amazing work\n",
    "    \"এই দৃশ্যটা দেখে আমি অবাক হয়ে গেছি।\",  # I was surprised to see this scene\n",
    "    \"ভগ্যিস ও মানুষ হয়ে জন্মায়নি.\",  # I love you\n",
    "    \"ভোটের হার কম হলে দোষ, বেশি হলে দোষ, ভোটের সময় মারামারি না হওয়াটাও দোষের, আসলে সমালোচকরা কী চায় ??\", \n",
    "]\n",
    "\n",
    "print(f\"📝 Prepared {len(sample_texts)} sample texts for testing\")\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    print(f\"{i}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e2df37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T18:46:30.920495Z",
     "iopub.status.busy": "2025-07-19T18:46:30.920167Z",
     "iopub.status.idle": "2025-07-19T18:46:35.280659Z",
     "shell.execute_reply": "2025-07-19T18:46:35.279384Z"
    },
    "papermill": {
     "duration": 4.366742,
     "end_time": "2025-07-19T18:46:35.282637",
     "exception": false,
     "start_time": "2025-07-19T18:46:30.915895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🚀 PERFORMING INFERENCE ON SAMPLE TEXTS\n",
      "============================================================\n",
      "🔮 Processing 7 texts for inference...\n",
      "✅ Inference completed successfully\n",
      "\n",
      "--- INFERENCE RESULTS ---\n",
      "Format: Text | Predicted Emotion | Predicted Intensity\n",
      "--------------------------------------------------------------------------------\n",
      "1. আমি খুব খুশি আজকে।...\n",
      "   → Emotion: happy (ID: 3)\n",
      "   → Intensity: 2.0 (ID: 2)\n",
      "\n",
      "2. এটা খুব দুঃখজনক খবর।...\n",
      "   → Emotion: sad (ID: 4)\n",
      "   → Intensity: 2.0 (ID: 2)\n",
      "\n",
      "3. আল্লাহ তাদের সাহায্য করুন, আর জালিমদের ধ্বংস করুন,...\n",
      "   → Emotion: fear (ID: 2)\n",
      "   → Intensity: 2.0 (ID: 2)\n",
      "\n",
      "4. আবার হরতাল করে মানুষের মধ্যে আতংক তৈরি করার পাঁয়তা...\n",
      "   → Emotion: angry (ID: 0)\n",
      "   → Intensity: 1.0 (ID: 1)\n",
      "\n",
      "5. এই দৃশ্যটা দেখে আমি অবাক হয়ে গেছি।...\n",
      "   → Emotion: surprise (ID: 5)\n",
      "   → Intensity: 2.0 (ID: 2)\n",
      "\n",
      "6. ভগ্যিস ও মানুষ হয়ে জন্মায়নি....\n",
      "   → Emotion: fear (ID: 2)\n",
      "   → Intensity: 0.0 (ID: 0)\n",
      "\n",
      "7. ভোটের হার কম হলে দোষ, বেশি হলে দোষ, ভোটের সময় মারা...\n",
      "   → Emotion: angry (ID: 0)\n",
      "   → Intensity: 1.0 (ID: 1)\n",
      "\n",
      "💾 Results saved to: inference_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# PERFORM INFERENCE ON SAMPLE TEXTS\n",
    "################################################################################\n",
    "\n",
    "# Run inference\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🚀 PERFORMING INFERENCE ON SAMPLE TEXTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_df, emotion_logits, intensity_logits = predict_emotions_and_intensities(\n",
    "    sample_texts, model, tokenizer, batch_size=8\n",
    ")\n",
    "\n",
    "# Display results in the same format as training\n",
    "print(\"\\n--- INFERENCE RESULTS ---\")\n",
    "print(\"Format: Text | Predicted Emotion | Predicted Intensity\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for idx, row in results_df.iterrows():\n",
    "    print(f\"{idx+1}. {row['text'][:50]}...\")\n",
    "    print(f\"   → Emotion: {row['predicted_emotion']} (ID: {row['predicted_emotion_id']})\")\n",
    "    print(f\"   → Intensity: {row['predicted_intensity']} (ID: {row['predicted_intensity_id']})\")\n",
    "    print()\n",
    "\n",
    "# Save results to CSV (same as training)\n",
    "output_file = \"inference_predictions.csv\"\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"💾 Results saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26b7284",
   "metadata": {
    "papermill": {
     "duration": 0.003405,
     "end_time": "2025-07-19T18:46:35.289558",
     "exception": false,
     "start_time": "2025-07-19T18:46:35.286153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7862579,
     "sourceId": 12519047,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 50.160347,
   "end_time": "2025-07-19T18:46:38.137861",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-19T18:45:47.977514",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
